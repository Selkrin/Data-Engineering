{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project:\n",
    "\n",
    "Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do \"Ask HN\" or \"Show HN\" receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Open the Hacker News Posts dataset\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(hn_header)\n",
    "print(\"\")\n",
    "print(hn[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "Number of rows: 20100\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "# start & end (integers representing start and end of slice)\n",
    "# row_and_columns (Boolean, default is False)\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print(\"\\n\") # Adds a new (empty) line after each row\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows:\", len(dataset))\n",
    "        print(\"Number of columns:\", len(dataset[0]))\n",
    "        \n",
    "explore_data(hn,0,2,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process\n",
    "- Detect inaccurate data, and correct or remove it.\n",
    "- Detect duplicate data, and remove the duplicates.\n",
    "- Check for any non-English posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in posts, by length of the rows:\n"
     ]
    }
   ],
   "source": [
    "# Find Errors in the data, by using the length of the rows\n",
    "print(\"Errors in posts, by length of the rows:\")\n",
    "for row in hn:\n",
    "    if len(row) != len(hn_header):\n",
    "        print(row)\n",
    "        print(\"Error row #:\", hn.index(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate posts: 0\n",
      "Number of unique posts: 20100\n"
     ]
    }
   ],
   "source": [
    "# Find any duplicate posts, based on the id number\n",
    "\n",
    "hn_duplicate_posts = []\n",
    "hn_unique_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    name = row[0]\n",
    "    if name in hn_unique_posts:\n",
    "        hn_duplicate_posts.append(name)\n",
    "    else:\n",
    "        hn_unique_posts.append(name)        \n",
    "        \n",
    "print(\"Number of duplicate posts:\", len(hn_duplicate_posts))\n",
    "print(\"Number of unique posts:\", len(hn_unique_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Checking for English Words leaving in some words with Emoji's and symbols\n",
    "def is_english(string):\n",
    "    non_ascii = 0\n",
    "    \n",
    "    for character in string:\n",
    "        if ord(character) > 127: # The first 127 characters are English\n",
    "            non_ascii += 1\n",
    "            \n",
    "    if non_ascii > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "print(is_english('Docs To Goâ„¢ Free Office Suite'))\n",
    "print(is_english('Instachat ðŸ˜œ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of some post titles:\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "Number of rows: 20097\n",
      "Number of columns: 7\n",
      "\n",
      "3 posts removed for non-English words.\n",
      "\n",
      "[['11365297', 'CryptÃ‚Â·oÃ‚Â·phobe', 'https://www.cryptophobia.com/', '4', '1', 'r0muald', '3/26/2016 11:41'], ['11459868', 'Today is 2Ã‚Â²/2Ã‚Â³/2?', '', '33', '6', 'sinak', '4/9/2016 4:14'], ['10606767', 'Dormir en el limbo: radiografÃƒ\\xada de Airbnb  EL ESPAÃƒ\\x91OL', 'http://datos.elespanol.com/proyectos/airbnb/', '1', '1', 'malditojavi', '11/21/2015 13:39']]\n"
     ]
    }
   ],
   "source": [
    "# Filter out the non-English posts by title\n",
    "hn_english = []\n",
    "hn_non_english = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if is_english(title):\n",
    "        hn_english.append(row)\n",
    "    else:\n",
    "        hn_non_english.append(row)\n",
    "        \n",
    "print(\"Examples of some post titles:\")\n",
    "explore_data(hn_english,0,2,True)\n",
    "print(\"\")\n",
    "print(len(hn) - len(hn_english), \"posts removed for non-English words.\")\n",
    "print(\"\")\n",
    "print(hn_non_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"Ask HN\" posts: 1744\n",
      "\"Ask HN\" posts make up 8.677 % of the overall posts.\n",
      "Number of \"Show HN\" posts: 1162\n",
      "\"Show HN\" posts make up 5.781 % of the overall posts.\n",
      "Number of other posts: 17191\n",
      "Other HN posts make up 85.527 % of the overall posts.\n",
      "\n",
      "Examples of some \"Ask HN\" posts:\n",
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14']]\n",
      "\n",
      "Examples of some \"Show HN\" posts:\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05']]\n"
     ]
    }
   ],
   "source": [
    "# Filter out posts with titles beginning with \"Ask HN\" or \"Show HN\"\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn_english:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Number of \"Ask HN\" posts:', len(ask_posts))\n",
    "ask_hn_percent = (len(ask_posts)/(len(hn)))*100\n",
    "print('\"Ask HN\" posts make up', round(ask_hn_percent, 3), \"% of the overall posts.\")\n",
    "\n",
    "print('Number of \"Show HN\" posts:', len(show_posts))\n",
    "show_hn_percent = (len(show_posts)/(len(hn)))*100\n",
    "print('\"Show HN\" posts make up', round(show_hn_percent, 3), \"% of the overall posts.\")\n",
    "\n",
    "print('Number of other posts:', len(other_posts))\n",
    "other_hn_percent = (len(other_posts)/(len(hn)))*100\n",
    "print('Other HN posts make up', round(other_hn_percent, 3), \"% of the overall posts.\")\n",
    "print(\"\")\n",
    "print('Examples of some \"Ask HN\" posts:')\n",
    "print(ask_posts[:3])\n",
    "print(\"\")\n",
    "print('Examples of some \"Show HN\" posts:')\n",
    "print(show_posts[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of comments on \"Ask HN\" posts: 24483\n",
      "The average number of comments on \"Ask HN\" posts: 14.038\n",
      "\n",
      "Total numbers of comments on \"Show HN\" posts: 11988\n",
      "The average number of comments on \"Show HN\" posts: 10.317\n",
      "\n",
      "\"Ask HN\" has 2.896 % more posts, than \"Show HN\"\n",
      "\"Ask HN\" has 204.229 % more comments, than \"Show HN\"\n"
     ]
    }
   ],
   "source": [
    "# Finding the total number of comments on \"Ask HN\" and \"Show HN\" posts\n",
    "# ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = row[4]\n",
    "    total_ask_comments = total_ask_comments + int(num_comments)\n",
    "    \n",
    "for row in show_posts:\n",
    "    num_comments = row[4]\n",
    "    total_show_comments = total_show_comments + int(num_comments)\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print('Total numbers of comments on \"Ask HN\" posts:', total_ask_comments)\n",
    "print('The average number of comments on \"Ask HN\" posts:', round(avg_ask_comments, 3))\n",
    "print(\"\")\n",
    "print('Total numbers of comments on \"Show HN\" posts:', total_show_comments)\n",
    "print('The average number of comments on \"Show HN\" posts:', round(avg_show_comments, 3))\n",
    "print(\"\")\n",
    "print('\"Ask HN\" has', round(ask_hn_percent - show_hn_percent, 3), '% more posts, than \"Show HN\"')\n",
    "ask_show_percent = (total_ask_comments / total_show_comments)*100\n",
    "print('\"Ask HN\" has', round(ask_show_percent, 3) , '% more comments, than \"Show HN\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Show posts or Ask posts receive more comments on average?\n",
    "I calculated the overall average of \"Ask HN\" posts, \"Show HN\" posts, and all the other posts on the Hacker News.\n",
    "\n",
    "Even though \"Ask HN\" has about 3% more (582 more) overall posts than \"Show HN\" it has a little more than double the comments.\n",
    "\n",
    "----\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "- Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of the result_list:\n",
      "[['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29], ['5/2/2016 10:14', 1]]\n",
      "\n",
      "Number of posts, by the hour:\n",
      "('00:00', 55)\n",
      "('01:00', 60)\n",
      "('02:00', 58)\n",
      "('03:00', 54)\n",
      "('04:00', 47)\n",
      "('05:00', 46)\n",
      "('06:00', 44)\n",
      "('07:00', 34)\n",
      "('08:00', 48)\n",
      "('09:00', 45)\n",
      "('10:00', 59)\n",
      "('11:00', 58)\n",
      "('12:00', 73)\n",
      "('13:00', 85)\n",
      "('14:00', 107)\n",
      "('15:00', 116)\n",
      "('16:00', 108)\n",
      "('17:00', 100)\n",
      "('18:00', 109)\n",
      "('19:00', 110)\n",
      "('20:00', 80)\n",
      "('21:00', 109)\n",
      "('22:00', 71)\n",
      "('23:00', 68)\n",
      "\n",
      "Number of comments, by the hour:\n",
      "('00:00', 447)\n",
      "('01:00', 683)\n",
      "('02:00', 1381)\n",
      "('03:00', 421)\n",
      "('04:00', 337)\n",
      "('05:00', 464)\n",
      "('06:00', 397)\n",
      "('07:00', 267)\n",
      "('08:00', 492)\n",
      "('09:00', 251)\n",
      "('10:00', 793)\n",
      "('11:00', 641)\n",
      "('12:00', 687)\n",
      "('13:00', 1253)\n",
      "('14:00', 1416)\n",
      "('15:00', 4477)\n",
      "('16:00', 1814)\n",
      "('17:00', 1146)\n",
      "('18:00', 1439)\n",
      "('19:00', 1188)\n",
      "('20:00', 1722)\n",
      "('21:00', 1745)\n",
      "('22:00', 479)\n",
      "('23:00', 543)\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with two elements (time created and number of comments)\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    two_elements = [created_at, num_comments]\n",
    "    result_list.append(two_elements)\n",
    "\n",
    "# Create dictionaries: number of posts by hour and number of comments by hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    date_time = row[0]\n",
    "    date_time = dt.datetime.strptime(date_time, \"%m/%d/%Y %H:%M\")\n",
    "    post_time = date_time.strftime(\"%H:00\")\n",
    "    if post_time not in counts_by_hour:\n",
    "        counts_by_hour[post_time] = 1\n",
    "        comments_by_hour[post_time] = int(row[1])\n",
    "    else:\n",
    "        counts_by_hour[post_time] += 1\n",
    "        comments_by_hour[post_time] += int(row[1])\n",
    "\n",
    "print(\"Example of the result_list:\")\n",
    "print(result_list[:3])\n",
    "print(\"\")\n",
    "# Convert the dictionary into a list of tuples, so it can be sorted\n",
    "counts_by_hour_list = sorted([(k,v) for k, v in counts_by_hour.items()])\n",
    "print(\"Number of posts, by the hour:\")\n",
    "for row in counts_by_hour_list:\n",
    "    print(row)\n",
    "print(\"\")\n",
    "comments_by_hour_list = sorted([(k,v) for k, v in comments_by_hour.items()])\n",
    "print(\"Number of comments, by the hour:\")\n",
    "for row in comments_by_hour_list:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00:00', 8.127272727272727]\n",
      "['01:00', 11.383333333333333]\n",
      "['02:00', 23.810344827586206]\n",
      "['03:00', 7.796296296296297]\n",
      "['04:00', 7.170212765957447]\n",
      "['05:00', 10.08695652173913]\n",
      "['06:00', 9.022727272727273]\n",
      "['07:00', 7.852941176470588]\n",
      "['08:00', 10.25]\n",
      "['09:00', 5.5777777777777775]\n",
      "['10:00', 13.440677966101696]\n",
      "['11:00', 11.051724137931034]\n",
      "['12:00', 9.41095890410959]\n",
      "['13:00', 14.741176470588234]\n",
      "['14:00', 13.233644859813085]\n",
      "['15:00', 38.5948275862069]\n",
      "['16:00', 16.796296296296298]\n",
      "['17:00', 11.46]\n",
      "['18:00', 13.20183486238532]\n",
      "['19:00', 10.8]\n",
      "['20:00', 21.525]\n",
      "['21:00', 16.009174311926607]\n",
      "['22:00', 6.746478873239437]\n",
      "['23:00', 7.985294117647059]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of comments received by the hour created\n",
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_comments = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, avg_comments])\n",
    "\n",
    "sorted_avg_by_hour = sorted(avg_by_hour)\n",
    "for row in sorted_avg_by_hour:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 hours of \"Ask HN\" posts comments\n",
      "15:00 EST: 38.59 average comments per post.\n",
      "02:00 EST: 23.81 average comments per post.\n",
      "20:00 EST: 21.52 average comments per post.\n",
      "16:00 EST: 16.80 average comments per post.\n",
      "21:00 EST: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "# Sorting the list of lists and printing the five highest values\n",
    "# in a format that's easier to read\n",
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    first_element = row[0]\n",
    "    second_element = row[1]\n",
    "    swap_avg_by_hour.append([second_element, first_element])\n",
    "    \n",
    "# Sort the list\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "# Print the five highest values\n",
    "print('The top 5 hours of \"Ask HN\" posts comments')\n",
    "for row in sorted_swap[:5]:\n",
    "    hour_element = dt.datetime.strptime(row[1], \"%H:%M\")\n",
    "    hour_element = hour_element.strftime(\"%H:%M\")\n",
    "    result_string = \"{} EST: {:.2f} average comments per post.\".format(hour_element, row[0])\n",
    "    print(result_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which hours creating a post have a higher chance of receiving comments?\n",
    "\n",
    "- 15:00 EST (3pm EST) has the Highest average number of comments, per post.\n",
    "- Followed by 02:00 EST (2am EST) with the second highest.\n",
    "----\n",
    "- With 3pm being the highest and 4pm the fourth highest, it looks like posts around this time period have the highest chance of receiveing comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
